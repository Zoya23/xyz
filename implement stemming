# Code Generated by Sidekick is for learning and experimentation purposes only.
import pandas as pd
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import string

# Download necessary NLTK resources
nltk.download('punkt')
nltk.download('stopwords')

# Load the dataset
data = {'messages': [
    "The cats are playing in the garden.",
    "He is running quickly to catch the bus.",
    "The boys are enjoying their game.",
    "She was reading a book.",
    "I love to eat apples and bananas."
]}
df = pd.DataFrame(data)

# Initialize the stemmer and stop words
stemmer = PorterStemmer()
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    # Tokenization
    tokens = word_tokenize(text)
    # Stop-words Removal
    tokens = [word for word in tokens if word.lower() not in stop_words]
    # Text Normalization (Lowercasing and Removing punctuation)
    tokens = [word.lower() for word in tokens if word.isalnum()]
    # Stemming
    tokens = [stemmer.stem(word) for word in tokens]
    return ' '.join(tokens)

# Apply the pre-processing pipeline
df['processed_messages'] = df['messages'].apply(preprocess_text)

# Display the result
print(df[['messages', 'processed_messages']])
print("\n \n")

# Code Generated by Sidekick is for learning and experimentation purposes only.
import pandas as pd
import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import string

# Download necessary NLTK resources
nltk.download('punkt')
nltk.download('stopwords')

# Load the dataset
data = {'messages': [
    """ham Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine
there got amore wat...""",
    """ham Ok lar... Joking wif u oni...""",
    """spam Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121
to receive entry question(std txt rate)T&C's apply 08452810075over18's""",
    """ham U dun say so early hor. U c already then say.""",
    """ham Nah I don't think he goes to usf, he lives around here though"""
]}
df = pd.DataFrame(data)

# Initialize the stemmer and stop words
stemmer = PorterStemmer()
stop_words = set(stopwords.words('english'))

def preprocess_text(text):
    # Tokenization
    tokens = word_tokenize(text)
    # Stop-words Removal
    tokens = [word for word in tokens if word.lower() not in stop_words]
    # Text Normalization (Lowercasing and Removing punctuation)
    tokens = [word.lower() for word in tokens if word.isalnum()]
    # Stemming
    tokens = [stemmer.stem(token) for token in tokens]
    return ' '.join(tokens)

# Apply the pre-processing pipeline
df['processed_messages'] = df['messages'].apply(preprocess_text)

# Display the result
print(df[['messages', 'processed_messages']])
print("\n \n")
