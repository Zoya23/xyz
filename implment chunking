# Code Generated by Sidekick is for learning and experimentation purposes only.
def chunk_list(data, chunk_size):
    """Yield successive chunk_size-sized chunks from data."""
    for i in range(0, len(data), chunk_size):
        yield data[i:i + chunk_size]

# Example usage:
data = [1, 2, 3, 4, 5, 6, 7, 8, 9]
chunks = list(chunk_list(data, 3))
print(chunks)


def chunk_text(text, chunk_size):
    """Break text into chunks of specified character length."""
    for i in range(0, len(text), chunk_size):
        yield text[i:i + chunk_size]

# Example usage: "cha, rac, ter"
text = "This is an example of chunking text into smaller pieces."
chunks = list(chunk_text(text, 10))
print(chunks)


def read_file_in_chunks(file_path, chunk_size=1024):
    """Read a file in chunks."""
    with open(file_path, 'rb') as f:
        while True:
            chunk = f.read(chunk_size)
            if not chunk:
                break
            yield chunk

for chunk in read_file_in_chunks('/content/SMSSpamCollection'):
    print(chunk)

# Code Generated by Sidekick is for learning and experimentation purposes only.
import nltk
from nltk import pos_tag, word_tokenize, RegexpParser

# Ensure NLTK resources are available
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

# Function to perform chunking and phrase extraction
def chunk_and_extract_phrases(sentence):
    # Step 1: Tokenize the input sentence
    tokens = word_tokenize(sentence)

    # Step 2: Perform part-of-speech tagging
    tagged_tokens = pos_tag(tokens)

    # Step 3: Define a grammar for chunking
    grammar = """
    NP: {<DT>?<JJ>*<NN.*>} # Noun Phrase
    VP: {<VB.*><NP|PP>*} # Verb Phrase
    AP: {<JJ.*>+} # Adjective Phrase
    AdvP: {<RB.*>+} # Adverbial Phrase
    PP: {<IN><NP>} # Prepositional Phrase
    """

    # Step 4: Create a chunk parser using the defined grammar
    chunk_parser = RegexpParser(grammar)

    # Step 5: Parse the tagged tokens to get chunked output
    chunked = chunk_parser.parse(tagged_tokens)

    # Step 6: Extract and print noun phrases and verb phrases
    noun_phrases = []
    verb_phrases = []

    for subtree in chunked.subtrees():
        if subtree.label() == 'NP':
            noun_phrases.append(' '.join(word for word, tag in subtree.leaves()))
        elif subtree.label() == 'VP':
            verb_phrases.append(' '.join(word for word, tag in subtree.leaves()))

    # Print the results
    print("Noun Phrases:")
    for np in noun_phrases:
        print(f"- {np}")

    print("\nVerb Phrases:")
    for vp in verb_phrases:
        print(f"- {vp}")

# Step 7: Get user input
user_input = input("Please enter a sentence: ")

# Step 8: Process the input sentence
chunk_and_extract_phrases(user_input)
